{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHKVhnIwfkgK"
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformer import Transformer\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_file = 'English.txt'\n",
        "hindi_file = 'Hindi.txt'"
      ],
      "metadata": {
        "id": "4cuBJWsk-b_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "START_TOKEN = ''\n",
        "PADDING_TOKEN = ''\n",
        "END_TOKEN = ''\n",
        "\n",
        "hindi_vocabulary = [\n",
        "    START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
        "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', '?', '।', '॥',\n",
        "    'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ओ', 'औ',\n",
        "    'क', 'ख', 'ग', 'घ', 'ङ',\n",
        "    'च', 'छ', 'ज', 'झ', 'ञ',\n",
        "    'ट', 'ठ', 'ड', 'ढ', 'ण',\n",
        "    'त', 'थ', 'द', 'ध', 'न',\n",
        "    'प', 'फ', 'ब', 'भ', 'म',\n",
        "    'य', 'र', 'ल', 'व',\n",
        "    'श', 'ष', 'स', 'ह',\n",
        "    'क्ष', 'त्र', 'ज्ञ',\n",
        "    'ा', 'ि', 'ी', 'ु', 'ू', 'े', 'ै', 'ो', 'ौ', 'ं', 'ँ', 'ः', 'ऽ', '्',\n",
        "    '०', '१', '२', '३', '४', '५', '६', '७', '८', '९',\n",
        "    PADDING_TOKEN, END_TOKEN\n",
        "]\n",
        "\n",
        "english_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
        "                        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
        "                        ':', '<', '=', '>', '?', '@',\n",
        "                        '[', '\\\\', ']', '^', '_', '`',\n",
        "                        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
        "                        'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x',\n",
        "                        'y', 'z',\n",
        "                        '{', '|', '}', '~', PADDING_TOKEN, END_TOKEN]\n"
      ],
      "metadata": {
        "id": "MAEZ-z2I-fX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_hindi = {k:v for k,v in enumerate(hindi_vocabulary)}\n",
        "hindi_to_index = {v:k for k,v in enumerate(hindi_vocabulary)}\n",
        "index_to_english = {k:v for k,v in enumerate(english_vocabulary)}\n",
        "english_to_index = {v:k for k,v in enumerate(english_vocabulary)}"
      ],
      "metadata": {
        "id": "DcpVUTGF-h3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(english_file, 'r') as file:\n",
        "    english_sentences = file.readlines()\n",
        "with open(hindi_file, 'r') as file:\n",
        "    hindi_sentences = file.readlines()"
      ],
      "metadata": {
        "id": "AG3cFUCH-mVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_sentences = [sentence.rstrip('\\n').lower() for sentence in english_sentences]\n",
        "hindi_sentences = [sentence.rstrip('\\n') for sentence in hindi_sentences]"
      ],
      "metadata": {
        "id": "yI0cZdN9-n3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3too6wsn-pp_",
        "outputId": "e94e931c-7822-46ec-80cc-1c3c910f73c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['4 days after the massive tsunami struck japan, hopes of finding anyone still alive were fading.',\n",
              " 'what was completing the square?',\n",
              " 'i have already done my work.',\n",
              " 'national mental health programme',\n",
              " 'menu',\n",
              " 'the inflation rate is apparently in the ascending degree.',\n",
              " 'a sludge of blood in the vessel causes absruction to blood flow.',\n",
              " 'device',\n",
              " 'harkat - ul - jihad al - islami',\n",
              " 'url …']"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hindi_sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P90frU3Q-rMg",
        "outputId": "887b3428-8665-4464-90a8-b78da6f9f3f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['बडे पैमाने पर सुनामी से प्रभावीत जापान में 4 दिनो बाद कोई अभी तक जिंदा होने की आशाएँ लुप्त हो रही थी।',\n",
              " 'वर्ग का पूर्णा क्या था?',\n",
              " 'मैं अपना काम कर चुका हूँ।',\n",
              " 'राष्ट्रीय मनः स्वास्थ्य कार्यक्रम',\n",
              " 'क्रियावली',\n",
              " 'मुद्रास्फीति की दर प्रत्यक्ष रूप से उपरली डिग्री में है।',\n",
              " 'वाहिका में रूधिर अवपंक रक्त प्रवाह में अवरोध का कारण है',\n",
              " 'उपकरण',\n",
              " 'हरकत-उल-जिहाद-ए-इस्लामी',\n",
              " 'URL …']"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PERCENTILE = 97\n",
        "print( f\"{PERCENTILE}th percentile length Hindi: {np.percentile([len(x) for x in hindi_sentences], PERCENTILE)}\" )\n",
        "print( f\"{PERCENTILE}th percentile length English: {np.percentile([len(x) for x in english_sentences], PERCENTILE)}\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_ccQHiD-tq4",
        "outputId": "d37f16a8-5454-4be7-91f2-f46f830f7c1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97th percentile length Hindi: 267.0\n",
            "97th percentile length English: 271.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_length = 200\n",
        "\n",
        "def is_valid_tokens(sentence, vocab):\n",
        "    for token in list(set(sentence)):\n",
        "        if token not in vocab:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def is_valid_length(sentence, max_sequence_length):\n",
        "    return len(list(sentence)) < (max_sequence_length - 1) # need to re-add the end token so leaving 1 space\n",
        "\n",
        "valid_sentence_indicies = []\n",
        "for index in range(len(hindi_sentences)):\n",
        "    hindi_sentence, english_sentence = hindi_sentences[index], english_sentences[index]\n",
        "    if is_valid_length(hindi_sentence, max_sequence_length) \\\n",
        "      and is_valid_length(english_sentence, max_sequence_length) \\\n",
        "      and is_valid_tokens(hindi_sentence, hindi_vocabulary):\n",
        "        valid_sentence_indicies.append(index)\n",
        "\n",
        "print(f\"Number of sentences: {len(hindi_sentences)}\")\n",
        "print(f\"Number of valid sentences: {len(valid_sentence_indicies)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-nbvkYN-wuk",
        "outputId": "07792a50-cdc0-497b-bb48-6fc3d756fcb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences: 200000\n",
            "Number of valid sentences: 118218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hindi_sentences = [hindi_sentences[i] for i in valid_sentence_indicies]\n",
        "english_sentences = [english_sentences[i] for i in valid_sentence_indicies]"
      ],
      "metadata": {
        "id": "jP-I-wFR-zVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hindi_sentence[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rZm7WQJX-18U",
        "outputId": "aa536809-ef73-4215-8dc3-e8e7f83ba8fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'उसी क'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d_model = 512\n",
        "batch_size = 30\n",
        "ffn_hidden = 2048\n",
        "num_heads = 8\n",
        "drop_prob = 0.1\n",
        "num_layers = 1\n",
        "max_sequence_length = 200\n",
        "kn_vocab_size = len(hindi_vocabulary)\n",
        "\n",
        "transformer = Transformer(d_model,\n",
        "                          ffn_hidden,\n",
        "                          num_heads,\n",
        "                          drop_prob,\n",
        "                          num_layers,\n",
        "                          max_sequence_length,\n",
        "                          kn_vocab_size,\n",
        "                          english_to_index,\n",
        "                          hindi_to_index,\n",
        "                          START_TOKEN,\n",
        "                          END_TOKEN,\n",
        "                          PADDING_TOKEN)"
      ],
      "metadata": {
        "id": "d_xk6gn8-5Rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wavZ0Rl-8_V",
        "outputId": "09783cd1-4e17-4a97-d441-1321088e20ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): Encoder(\n",
              "    (sentence_embedding): SentenceEmbedding(\n",
              "      (embedding): Embedding(69, 512)\n",
              "      (position_encoder): PositionalEncoding()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (layers): SequentialEncoder(\n",
              "      (0): EncoderLayer(\n",
              "        (attention): MultiHeadAttention(\n",
              "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (norm1): LayerNormalization()\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (ffn): PositionwiseFeedForward(\n",
              "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (norm2): LayerNormalization()\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (sentence_embedding): SentenceEmbedding(\n",
              "      (embedding): Embedding(105, 512)\n",
              "      (position_encoder): PositionalEncoding()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (layers): SequentialDecoder(\n",
              "      (0): DecoderLayer(\n",
              "        (self_attention): MultiHeadAttention(\n",
              "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (layer_norm1): LayerNormalization()\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (encoder_decoder_attention): MultiHeadCrossAttention(\n",
              "          (kv_layer): Linear(in_features=512, out_features=1024, bias=True)\n",
              "          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (layer_norm2): LayerNormalization()\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (ffn): PositionwiseFeedForward(\n",
              "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm3): LayerNormalization()\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=512, out_features=107, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "sfGrs34O_AIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(Dataset):\n",
        "\n",
        "    def __init__(self, english_sentences, hindi_sentences):\n",
        "        self.english_sentences = english_sentences\n",
        "        self.hindi_sentences = hindi_sentences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.english_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.english_sentences[idx], self.hindi_sentences[idx]"
      ],
      "metadata": {
        "id": "JzZJL3b2_Ctl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TextDataset(english_sentences, hindi_sentences)"
      ],
      "metadata": {
        "id": "HlV8XMD1_Ean"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChyR83jc_HXg",
        "outputId": "1b0c2932-a809-447a-fa7d-7d07f9c1aac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "118218"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APjPFNuL_I1h",
        "outputId": "13a05373-0d07-4fd0-854f-afa92a874665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('the inflation rate is apparently in the ascending degree.',\n",
              " 'मुद्रास्फीति की दर प्रत्यक्ष रूप से उपरली डिग्री में है।')"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset, batch_size)\n",
        "iterator = iter(train_loader)"
      ],
      "metadata": {
        "id": "_1pMKPc-_LmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for batch_num, batch in enumerate(iterator):\n",
        "    print(batch)\n",
        "    if batch_num > 3:\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCcEZC84_NsB",
        "outputId": "b732108a-5cb3-4aca-a07e-1fc7d404e91f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('4 days after the massive tsunami struck japan, hopes of finding anyone still alive were fading.', 'what was completing the square?', 'i have already done my work.', 'national mental health programme', 'menu', 'the inflation rate is apparently in the ascending degree.', 'a sludge of blood in the vessel causes absruction to blood flow.', 'device', 'harkat - ul - jihad al - islami', 'how do i raise the self - esteem of a child', 'the following is a typical example of many telugu folk songs addressed to the moon.', 'note', 'sterilisation', 'no title', 'select', 'preserve', \"it 's been my observation that most people get ahead during the time that others waste.\", 'emergency contraception can be use only up to 72 hours (3days) after the occurrence of unprotected sex.', 'the constitution, which provides for certain basic safeguards which have been called fundamental rights, also provides for a quick and inexpensive remedy for the enforcement of such rights.', 'agency', 'market intermediary', 'nagpur district', 'uterine rupture may be during curretage of uterus.', 'to asking for something in a pleading manner', 'this is an extraordinary case.', 'giant hornbill', 'only approved contractors have been allowed to bid for the contract.', 'tax capitalisation may be used as a form of assistance to the needy industries.', 'disorder', 'cerement'), ('बडे पैमाने पर सुनामी से प्रभावीत जापान में 4 दिनो बाद कोई अभी तक जिंदा होने की आशाएँ लुप्त हो रही थी।', 'वर्ग का पूर्णा क्या था?', 'मैं अपना काम कर चुका हूँ।', 'राष्ट्रीय मनः स्वास्थ्य कार्यक्रम', 'क्रियावली', 'मुद्रास्फीति की दर प्रत्यक्ष रूप से उपरली डिग्री में है।', 'वाहिका में रूधिर अवपंक रक्त प्रवाह में अवरोध का कारण है', 'उपकरण', 'हरकत-उल-जिहाद-ए-इस्लामी', 'किसी बच्चे का स्वाभिमान बढाना', 'निम्नलिखित तेलुगु गीत चंद्रमा से संबंधित लोक गीतों का एक उदाहरण हैं।', 'व्याख्या', 'विसंक्रमण', 'कोई शीर्षक नहीं', 'चुनें', 'संभालना', 'मैंने देखा है कि ज्यादातर लोग उस समय आगे निकल जाते हैं जब दूसरे समय को बरबाद कर रहे होते हैं।', 'असुरक्षित संभोग क्रिया के बाद 72 घंटे (3 दिन) तक ही आपाती गर्भ निरोधकों का प्रयोग किया जा सकता है।', 'हमारे संविधान में, जिसमें कुछ आधारभूत रक्षोपाय दिए गए हैं जिन्हें मूल अधिकार कहा गया है, इन अधिकारों के प्रवर्तन के लिए त्वरित एवं कमखर्च उपाय की व्यवस्था भी की गई है।', 'सबील', 'विपणन बिचौलिया', 'नागपुर जिला', 'गर्भाश्य विदार गर्भाशय के क्यूरोटटेज के दौरान हो सकता है।', 'विनातिपूर्वक कुछ माँगना', 'यह एक असाधारण घटना है।', 'विशालकाय होर्नबिल', 'ठेके के लिए बोली लगाने की आज्ञा सिर्फ अनुमोदित ठेकेदारों को ही दी गयी है।', 'कर का पूंजीकरण जरुरतमंद उद्योगों को सहायता प्रदान करने का एक उपाय हो सकता है।', 'आकुलत्व', 'प्रेत-पट')]\n",
            "[('what is the matter with you? why do you not help one another?', 'the sutras could play that part once again in the fissured world of the modern thinker.', 'the lion, king of the forest, was resting under a tree.', 'uncoloured', 'but denied [them] and turned away,', 'there were no fire - engines within fifty miles.', 'the train ran off the tracks.', 'failed to load image information', 'pause', 'australian', 'direct tax', 'in which they will remain forever; in it they will find neither a protector nor any supporter.', 'some major rivers in himalaya are sindhu, ganga, brahmaputra and yangtez.', 'sycophantic', 'macerate', 'outdated', 'points: 122 year: july - september, 2008', 'but it will be ignored by the most unfortunate,', 'technology is built not so much by individuals but by organizations.', 'a process of straightening fractured bones by using wires or pins.', 'it gives voice to the downtrodden and dispossessed.', 'less than or whatever?', \"part that we 're subtracting from the other fraction part was smaller.\", 'credit delivery through micro credit organizations / self help groups', 'ajay maken', 'to them they are a symbol of status and security.', 'herbalife', 'europe / kiev', 'life is hard hi the rural areas.', 'penetration'), ('(अरे कमबख्तों) अब तुम्हें क्या होगा कि एक दूसरे की मदद नहीं करते', 'आधुनिक चिनतकों की मतविभाजित दुनिया में वे सूत्र एक बार फिर अपनी भूमिका निभा सकते हैं।', 'जंगल का राजा सिंह एक पेड के नीचे सुस्ता रहा था।', 'निरङ्ग', 'मगर झुठलाया और (ईमान से) मुँह फेरा', 'आसपास पचास मील तक कहीं कोई आग बुझाने वाली मोटर थी ही नहीं।', 'ट्रेन पटरी से उतर गई।', 'छवि जानकारी लोड करने में असफल', 'ठहरें', 'आस्ट्रेलियाई-भाषा', 'प्रत्यक्ष कर/कराधान', 'जिसमें वह हमेशा अबदल आबाद रहेंगे न किसी को अपना सरपरस्त पाएँगे न मद्दगार', 'हिमालय की कुछ प्रमुख नदियों में शामिल हैं-सिंधु गंगा ब्रम्हपुत्र और यांगतेज।', 'खुशामदी', 'द्रवनिवेशन', 'अप्रचरित', 'अंक: 122 वर्ष: जुलाई-सितंबर, 2008', 'और बदबख्त उससे पहलू तही करेगा', 'प्रौद्योगिकी का निर्माण व्यक्तियों से कहीं अधिक संगठनों द्वारा किया जाता है।', 'तार या पिन का उपयोग करके टूटी हुई हड्डियों को सीधी करने की एक प्रक्रिया.', 'यह दबे-कुचलों और वंचितों की आवाज है।', 'कम से कम या जो कुछ भी?', 'जिसको हम दूसरे अंश भाग से घटा रहे थे', 'माइक्रो ऋण संगठनों/स्वयं सहायता समूहों के माध्यम से ऋण सुपुर्दगी', 'अजय माकन', 'उनके लिए वे सम्मान और सुरक्ष्ज्ञज्ञ के प्रतीक हैं।', 'हर्बालाइफ', 'यूरोप/केव', 'ग्रामीण क्षेत्रों में लोगों को कठोर जीवन जीना होता है।', 'ज्ञान')]\n",
            "[('international financial centre', \"'' what makes you think so.\", 'restitution', 'the latter was published in the name of veluri sivarama sastry; a student of theirs.', 'apex level', 'depth:', 'signing is not supported by this cipher', 'it is no more than a suggestion, but it is worth pondering.', 'crisis', 'the state also has two major river systems - mahanadi and godawari and their tributaries that form a network of 3573 kms.', 'besides women members of the family, almost all the household articles come within its scope.', 'we have to attract meritorious students for doing phd.', 'so obviously if you have some energy, you do some work,', 'urban blocks', 'it is a device made for scanning photographic film directly into a computer without the use of any intermediate printmaking.', 'using ocrad binary:', 'any narrow definition of democracy, which tries to ignore realities, can only mean the growth of political ideas which are anti - democratic.', 'of his sin will be questioned that day neither man nor jinn.', \"similarly, there are a few 'white dwarfs' below the main sequence.\", 'other address label', 'constant demand', 'garbage can', 'select character', 'so which of the favors of your lord would you deny?', 'scent', 'the three of them lay down in the shade.', '1202', 'here hs wears no garb of a mumal or a sasui or a lila or a nuri but reveals himself without any symbolic cover as a seeker of truth and man of realisation.', 'campus', 'white book'), ('अंतर्राष्ट्रीय वित्तीय केन्द्र', 'महाशय भी सोच रहे थेमौत क्या है?', 'प्रत्यानयन', 'वे वेलूरि शिवराम शास्त्री के नाम से प्रकाशित हुए।', 'शीर्ष स्तर', 'गहराईः', 'हस्ताक्षर इस सिफर के द्वारा समर्थित नहीं है', 'यह केवल एक सुझाव मात्र था, किंतु है यह विचारणीय।', 'आपत्', 'राज्य में दो मुख्य नदी तंत्र भी हैं, महानदी तथा गोदावरी और उनकी सहायक नदियां जो 3573 कि. मी. के नेटवर्क का निर्माण करती हैं।', 'दायरे में परिवार की स्त्रियों से लेकर सभी घरेलू सामान तक आ जाते हैं।', 'हमें पी-एच. डी. करने के लिए मेधावी विद्यार्थियों को आर्कषत करना होगा।', 'तो जाहिर है यदि आप कुछ ऊर्जा है, तो आपको कुछ ऐसा काम,', 'शहरी खण्ड', 'यह एक तंत्र है जो बिना किसी बीच के मुद्रण वाले तंत्र के कंप्यूटर में सीधे छायाचित्रों वाली फिल्म को स्कैन करने के लिए बनाया गया है।', 'ओसीआरएडी द्विचर उपयोग मेंः', 'लोकतंत्र की किसी संकीर्ण परिभाषा से, जो यथार्थ स्थिति की अनदेखी करती है, केवल यही नतीजा निकलेगा कि लोकतंत्र-विरोधी राजनैतिक विचार पनपेंगे।', 'तो उस दिन न तो किसी इन्सान से उसके गुनाह के बारे में पूछा जाएगा न किसी जिन से', 'इसी प्रकार मुख्य अनुक्रम के नीचे कुछ सफेद बौने भी हैं।', 'अन्य पता लेबल', 'स्थिर मांग', 'कचरा डब्बा', 'अक्षर चुनें', 'अतः तुम दोनों अपने रब की अनुकम्पाओं में से किस-किस को झुठलाओगे?', 'गमक', 'तीनों छाया में लेटे।', '१२०२', 'यहाँ वे मूमल या ससुई या लीला या नूरी के वेष में धारण नहीं करते और अपने को, किसी अभिव्यंजित करते हैं।', 'परिसर', 'श्वेतपत्र')]\n",
            "[('he said that tremendous responsibilities would be entrusted on their shoulders at a very young age in civil services.', 'familiar with them.', 'khayalistan popularised the new genre called adab - i - lateef, which was originally the translation of light literature.', \"couldn 't access trash.\", 'america / tijuana', 'abandonment of claim', 'the local officials even used their discretion in protecting the rights of the wild tribes inhabiting these lands.', 'in recent years, both india and mexico have emerged as dynamic economies.', 'similar programmes exist for writers, artists, grass root innovators, nit students and inspired teachers.', 'it is true that iswarchandra opposed some of the social reforms of the day like widow remarriage, but he was not opposed to any and every progressive measure as such.', 'panda', 'nicolas léonard sadi carnot', '05 minutes', 'i do hope that, as you said, we shall contest every muslim seat.', '“and wait – we too are waiting. ”', 'when shekhar came back that evening, she reported to him all about her futile exercise.', 'symbol database', 'analytical study', 'fatuous', 'carefree', 'lady finger', 'of course, i can and do envisage a state where the police will not be necessary; but whether we shall succeed in realizing it, the future alone will show.', 'bosom', 'main memory', 'but they had to do it like the west, right? because we are setting up leagues.', 'the whole of the case of the sind hindu sabha is a negation of the principle of democracy, except in so far as joint electorates are demanded.', 'this might strike you as a strange career move,', 'display ipod properties ipod', 'shapeless', 'calm'), ('उन्होंने कहा कि सिविल सेवा में इतनी अल्पायु में उनके कंधों पर भारी जिम्मेदारी डाली जाएगी।', 'उन लोगों के साथ परिचित।', 'यह मूल रूप में हलके-फुलके साहित्य का अनुवाद था।', 'रद्दी पर पंहुच नहीं सका.', 'अमेरिका/तिजुआना', 'दावे का परित्याग', 'स्थानीय अधिकारी भी इस प्रकार की भूमि के निवासी जनजातियों के अधिकारों की रक्षा में अपनी इच्छानुसार व्यवहार करते थे।', 'हाल के वर्षों में, भारत और मैक्सिको दोनों गतिशील अर्थव्यवस्थाओं के रूप में उभरे हैं।', 'ऐसे ही कार्यक्रम लेखकों, कलाकारों, बुनियादी नवान्वेषकों, राष्ट्रीय प्रौद्योगिकी संस्थानों के विद्यार्थियों तथा प्रेरित अध्यापकों के लिए विद्यमान हैं।', 'यह सच है कि, ईश्वरचन्द्र गुप्त ने उस समय विधवा पुनर्विवाह जैसे कुछ सामाजिक सुधारों का विरोध किया, लेकिन किसी खास या सभी प्रगतिशील कदमों से उनकी विरोध न था।', 'पाँडा बिल्ली', 'सादी कार्नो', '05 मिनट', 'जैसा कि आपने कहा है, मुझे पूरी आशा है कि हम हर मुस्लिम बैठक के लिए लडेंगे।', 'तुम भी प्रतीक्षा करो, हम भी प्रतीक्षा कर रहे है। \"', 'शाम को शेखर के लौटने पर उसने सुबह का अपना अनभव बयान किया।', 'प्रतीक डेटाबेस', 'विश्लेषणात्मक अध्ययन', 'ऊटपटाँग', 'अचिंत', 'भिंडी', 'अवश्य ही मैं ऐसे राज्य की कल्पना कर सकता हूं और कता हूं, जिसमें पुलिस की जरूरत नहीं होगीः परन्तु यह कल्पना सफल होगी या नहीं, यह तो भविष्य ही बतायेगा।', 'वाम', 'मुख्य मेमोरी', 'लेकिन उन्हें ये सब पाश्चात्य तरीके से करना था, है न? क्योंकि हम लीग की नीव रख रहे थे.', 'मिले-जुले चुनाव कराने की मांग के अलावा सिंध हिंदू महासभा का सारा मामला लोकतंत्र के उसूलों के खिलाफ है।', 'यह आपको एक अजीब व्यवसाय लगेगा,', 'विशेषताएँ दिखाएँ', 'बेडौल', 'शांत होना')]\n",
            "[('wrap outgoing text at', 'kanjirappally', 'it was something of a miraculous nature that brought about this marriage.', 'therein calling for every fruit, secure.', 'asia / anadyr', 'classification:', 'a container for putting things in it.', 'smallness', 'if the court finds that the nuisance existed at the date of making the complaint, they will award you the reasonable costs incurred by you in bringing the action against the noise maker.', 'such items of trade which are not visible but traded.', 'so eight plus eight is sixteen.', 'tigris', 'magnetic disk unit', 'the state of being sane.', \"it is the privilege of kerala to herald varsha 's arrival into the country, around the first week of june.\", 'its interface available in hindi as well.', 'when you can do long - term planning,', 'construction of worksheds', 'propneustic', \"well, it 's no wonder, these days.'\", 'in april 1854 he was given the powers of a junior assistant under the assam code and the powers of a sadar amin and of deputy collector.', 'heart', 'surdas', \"and one day - i don 't know what happened -\", 'sty', 'the romans have been defeated.', 'during the days of non - cooperation a number of arabic and persian terms were created to indicate passive resistance.', 'category: architecture', 'for wholesale marketing, the fish can be packed in polythene lined gunny bags.', 'water'), ('बाहर जाने वाले टेक्स्ट को', 'कन्जिरपल्ली', 'शाह लतीफ की शादी कैसे हुई, यह भी एक विस्मयकारी बात है।', 'वे वहाँ निश्चिन्तता के साथ हर प्रकार के स्वादिष्ट फल मँगवाते होंगे', 'एशिया/एनाडिर', 'वर्गीकरणः', 'ऐसा पात्र जिसमें सामान रखा जा सके।', 'छोटापन', 'यदि कोर्ट यह निश्चित करे कि शिकायत करने के दिन शांति भंग की अवस्था विद्यमान थी तो वह आप को शोर करने वाले के विरुद्ध केस करने में हुए खर्च के लिए समुचित लागत दिए जाने का आदेश देगा।', 'ऐसे मद जिनका व्यापार तो होता है लेकिन जो दिखाई नहीं देते।', 'तो 8 जमा 8 है 16.', 'दजला नदी', 'चुंबकीय चक्रिका एकक', 'स्वस्थचित्त होने की अवस्था', 'जून के पहले सप्ताह में देश में वर्षा के आगमन की शुभ सूचना का संदेशवाहक केरल होता है।', 'इसका इण्टरफेस हिन्दी में भी उपलब्ध है।', 'तब आप दूरगामी योजनायें बना सकते हैं,', 'वर्कशेड निर्माण', 'अग्र रंध्री', 'इन दिनों क्या कुछ नहीं हो सकता।', '1854 में असम कोड के अन्तर्गत उन्हें जूनियर एसिस्टेंट के अधिकार दिये गये।', 'आसंग', 'सूरदास (हिंदीकुंज में)', 'और एक दिन-ना जाने क्या हुआ कि-', 'अंजना', 'रूमी निकटवर्ती क्षेत्र में पराभूत हो गए हैं।', 'असहयोग के दिनों में अनेक अरबी और फारसी शब्द पैदा किये गये थे जो निष्क्रिय प्रतिरोध को प्रकट करते थे।', 'श्रेणीःस्थापत्य', 'थोक बिक्री के लिए इसे पोलिथिन लाइन्ड गन्नी बैगों में पैक किया जा सकता है।', 'वाटर')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterian = nn.CrossEntropyLoss(ignore_index=hindi_to_index[PADDING_TOKEN],\n",
        "                                reduction='none')"
      ],
      "metadata": {
        "id": "IbF2HOuB_PSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# When computing the loss, we are ignoring cases when the label is the padding token\n",
        "for params in transformer.parameters():\n",
        "    if params.dim() > 1:\n",
        "        nn.init.xavier_uniform_(params)\n",
        "\n",
        "optim = torch.optim.Adam(transformer.parameters(), lr=1e-4)\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "yBqKjMS0_RWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NEG_INFTY = -1e9\n",
        "\n",
        "def create_masks(eng_batch, kn_batch):\n",
        "    num_sentences = len(eng_batch)\n",
        "    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length] , True)\n",
        "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
        "    encoder_padding_mask = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "    decoder_padding_mask_self_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "\n",
        "    for idx in range(num_sentences):\n",
        "      eng_sentence_length, kn_sentence_length = len(eng_batch[idx]), len(kn_batch[idx])\n",
        "      eng_chars_to_padding_mask = np.arange(eng_sentence_length + 1, max_sequence_length)\n",
        "      kn_chars_to_padding_mask = np.arange(kn_sentence_length + 1, max_sequence_length)\n",
        "      encoder_padding_mask[idx, :, eng_chars_to_padding_mask] = True\n",
        "      encoder_padding_mask[idx, eng_chars_to_padding_mask, :] = True\n",
        "      decoder_padding_mask_self_attention[idx, :, kn_chars_to_padding_mask] = True\n",
        "      decoder_padding_mask_self_attention[idx, kn_chars_to_padding_mask, :] = True\n",
        "      decoder_padding_mask_cross_attention[idx, :, eng_chars_to_padding_mask] = True\n",
        "      decoder_padding_mask_cross_attention[idx, kn_chars_to_padding_mask, :] = True\n",
        "\n",
        "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
        "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
        "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
        "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask"
      ],
      "metadata": {
        "id": "gGOQjhkP_Ufq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Hindi vocab size:\", len(hindi_to_index))\n",
        "print(\"Max index value in hindi_to_index:\", max(hindi_to_index.values()))\n",
        "print(\"Embedding weight shape:\", transformer.decoder.sentence_embedding.embedding.weight.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gawf2Vz4_Yvy",
        "outputId": "cf633386-6e1e-48fd-c758-0c53103f8052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hindi vocab size: 105\n",
            "Max index value in hindi_to_index: 106\n",
            "Embedding weight shape: torch.Size([105, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(hindi_to_index)\n",
        "current_size = transformer.decoder.sentence_embedding.embedding.weight.shape[0]\n",
        "\n",
        "if current_size <= max(hindi_to_index.values()):\n",
        "    new_weight = torch.nn.Parameter(\n",
        "        torch.randn(vocab_size + 5, transformer.decoder.sentence_embedding.embedding.weight.shape[1])\n",
        "    )\n",
        "    transformer.decoder.sentence_embedding.embedding = nn.Embedding.from_pretrained(new_weight, freeze=False)\n",
        "    print(f\" Resized embedding to {transformer.decoder.sentence_embedding.embedding.weight.shape}\")\n",
        "else:\n",
        "    print(\" Embedding size already large enough.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCUdcCDW_bh2",
        "outputId": "6b37c7e6-cd61-4c88-a081-0600cbbcde3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Resized embedding to torch.Size([110, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.train()\n",
        "transformer.to(device)\n",
        "total_loss = 0\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch}\")\n",
        "    iterator = iter(train_loader)\n",
        "    for batch_num, batch in enumerate(iterator):\n",
        "        transformer.train()\n",
        "        eng_batch, kn_batch = batch\n",
        "        encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_batch, kn_batch)\n",
        "        optim.zero_grad()\n",
        "        kn_predictions = transformer(eng_batch,\n",
        "                                     kn_batch,\n",
        "                                     encoder_self_attention_mask.to(device),\n",
        "                                     decoder_self_attention_mask.to(device),\n",
        "                                     decoder_cross_attention_mask.to(device),\n",
        "                                     enc_start_token=False,\n",
        "                                     enc_end_token=False,\n",
        "                                     dec_start_token=True,\n",
        "                                     dec_end_token=True)\n",
        "        labels = transformer.decoder.sentence_embedding.batch_tokenize(kn_batch, start_token=False, end_token=True)\n",
        "        loss = criterian(\n",
        "            kn_predictions.view(-1, kn_vocab_size).to(device),\n",
        "            labels.view(-1).to(device)\n",
        "        ).to(device)\n",
        "        valid_indicies = torch.where(labels.view(-1) == hindi_to_index[PADDING_TOKEN], False, True)\n",
        "        loss = loss.sum() / valid_indicies.sum()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        #train_losses.append(loss.item())\n",
        "        if batch_num % 100 == 0:\n",
        "            print(f\"Iteration {batch_num} : {loss.item()}\")\n",
        "            print(f\"English: {eng_batch[0]}\")\n",
        "            print(f\"Hindi Translation: {kn_batch[0]}\")\n",
        "            kn_sentence_predicted = torch.argmax(kn_predictions[0], axis=1)\n",
        "            predicted_sentence = \"\"\n",
        "            for idx in kn_sentence_predicted:\n",
        "              if idx == hindi_to_index[END_TOKEN]:\n",
        "                break\n",
        "              predicted_sentence += index_to_hindi[idx.item()]\n",
        "            print(f\"Hindi Prediction: {predicted_sentence}\")\n",
        "\n",
        "\n",
        "            transformer.eval()\n",
        "            kn_sentence = (\"\",)\n",
        "            eng_sentence = (\"should we go to the mall?\",)\n",
        "            for word_counter in range(max_sequence_length):\n",
        "                encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(eng_sentence, kn_sentence)\n",
        "                predictions = transformer(eng_sentence,\n",
        "                                          kn_sentence,\n",
        "                                          encoder_self_attention_mask.to(device),\n",
        "                                          decoder_self_attention_mask.to(device),\n",
        "                                          decoder_cross_attention_mask.to(device),\n",
        "                                          enc_start_token=False,\n",
        "                                          enc_end_token=False,\n",
        "                                          dec_start_token=True,\n",
        "                                          dec_end_token=False)\n",
        "                next_token_prob_distribution = predictions[0][word_counter] # not actual probs\n",
        "                next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
        "                next_token = index_to_hindi[next_token_index]\n",
        "                kn_sentence = (kn_sentence[0] + next_token, )\n",
        "                if next_token == END_TOKEN:\n",
        "                  break\n",
        "\n",
        "            print(f\"Evaluation translation (should we go to the mall?) : {kn_sentence}\")\n",
        "            print(\"-------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "mOwJkQh5_fPS",
        "outputId": "230343cb-370c-4679-f99b-abff17ca1f54",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AcceleratorError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAcceleratorError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-999331936.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1367\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1353\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m                     )\n\u001b[0;32m-> 1355\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1356\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAcceleratorError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.eval()\n",
        "def translate(eng_sentence):\n",
        "  eng_sentence = (eng_sentence,)\n",
        "  kn_sentence = (\"\",)\n",
        "  for word_counter in range(max_sequence_length):\n",
        "    encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(eng_sentence, kn_sentence)\n",
        "    predictions = transformer(eng_sentence,\n",
        "                              kn_sentence,\n",
        "                              encoder_self_attention_mask.to(device),\n",
        "                              decoder_self_attention_mask.to(device),\n",
        "                              decoder_cross_attention_mask.to(device),\n",
        "                              enc_start_token=False,\n",
        "                              enc_end_token=False,\n",
        "                              dec_start_token=True,\n",
        "                              dec_end_token=False)\n",
        "    next_token_prob_distribution = predictions[0][word_counter]\n",
        "    next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
        "    next_token = index_to_hindi[next_token_index]\n",
        "    kn_sentence = (kn_sentence[0] + next_token, )\n",
        "    if next_token == END_TOKEN:\n",
        "      break\n",
        "  return kn_sentence[0]"
      ],
      "metadata": {
        "id": "TLNH4VmV_5yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translation = translate(\"what should we do when the day starts?\")\n",
        "print(translation)"
      ],
      "metadata": {
        "id": "woh3nJ5xTE3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translation = translate(\"how is this the truth?\")\n",
        "print(translation)"
      ],
      "metadata": {
        "id": "t3EJKZSITIZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0UHVyBOCd52c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}